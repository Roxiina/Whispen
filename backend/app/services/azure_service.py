"""
Service Azure OpenAI pour transcription et r√©sum√©
G√®re les appels √† Whisper (local ou OpenAI) et GPT-4 (Azure)
"""

from openai import AzureOpenAI, OpenAI
from app.config import settings
import logging
import time
from typing import Optional, Dict, Any

logger = logging.getLogger(__name__)

# Import conditionnel de faster-whisper
try:
    from faster_whisper import WhisperModel
    FASTER_WHISPER_AVAILABLE = True
except ImportError:
    FASTER_WHISPER_AVAILABLE = False
    logger.warning("‚ö†Ô∏è faster-whisper not installed, local transcription unavailable")


class AzureOpenAIService:
    """Service pour interagir avec Azure OpenAI et Whisper local"""
    
    def __init__(self):
        """Initialise les clients Azure OpenAI, OpenAI et Whisper local"""
        try:
            # Client Azure OpenAI pour GPT-4 (r√©sum√©)
            self.azure_client = AzureOpenAI(
                api_key=settings.AZURE_OPENAI_API_KEY,
                api_version=settings.AZURE_OPENAI_API_VERSION,
                azure_endpoint=settings.AZURE_OPENAI_ENDPOINT
            )
            logger.info("‚úÖ Azure OpenAI client initialized successfully")
            
            # Client OpenAI standard pour Whisper (transcription)
            if settings.USE_OPENAI_WHISPER:
                self.openai_client = OpenAI(api_key=settings.OPENAI_API_KEY)
                logger.info("‚úÖ OpenAI client initialized for Whisper")
            else:
                self.openai_client = None
            
            # Mod√®le Whisper local avec faster-whisper
            if settings.USE_LOCAL_WHISPER:
                if not FASTER_WHISPER_AVAILABLE:
                    error_msg = "faster-whisper is not installed. Install it with: pip install faster-whisper==1.1.0"
                    logger.error(f"‚ùå {error_msg}")
                    raise ImportError(error_msg)
                    
                logger.info(f"üîÑ Loading Whisper model '{settings.WHISPER_MODEL_SIZE}'...")
                try:
                    self.whisper_model = WhisperModel(
                        settings.WHISPER_MODEL_SIZE,
                        device="cpu",  # Utilise CPU (changez en "cuda" si GPU disponible)
                        compute_type="int8"  # Optimisation pour CPU
                    )
                    logger.info("‚úÖ Local Whisper model loaded successfully")
                except Exception as model_error:
                    logger.error(f"‚ùå Failed to load Whisper model: {model_error}")
                    raise
            else:
                self.whisper_model = None
                
        except Exception as e:
            logger.error(f"‚ùå Failed to initialize clients: {e}")
            raise
    
    async def transcribe_audio(
        self, 
        audio_file_path: str, 
        language: Optional[str] = "fr"
    ) -> Dict[str, Any]:
        """
        Transcrit un fichier audio avec Whisper (local ou OpenAI)
        
        Args:
            audio_file_path: Chemin vers le fichier audio
            language: Code langue (fr, en, etc.)
        
        Returns:
            Dict contenant le texte transcrit et les m√©tadonn√©es
        """
        start_time = time.time()
        
        try:
            logger.info(f"üé§ Starting transcription for: {audio_file_path}")
            
            # Option 1: Whisper local avec faster-whisper
            if settings.USE_LOCAL_WHISPER and self.whisper_model:
                segments, info = self.whisper_model.transcribe(
                    audio_file_path,
                    language=language,
                    beam_size=5,
                    vad_filter=True  # Voice Activity Detection pour meilleure qualit√©
                )
                
                # Reconstruction du texte complet
                text = " ".join([segment.text for segment in segments])
                duration = info.duration
                detected_language = info.language
                
                processing_time = time.time() - start_time
                
                result = {
                    "text": text,
                    "language": detected_language,
                    "duration": duration,
                    "processing_time": processing_time,
                    "word_count": len(text.split())
                }
                
                logger.info(f"‚úÖ Local transcription completed in {processing_time:.2f}s - {result['word_count']} words")
                return result
            
            # Option 2: OpenAI API Whisper
            elif settings.USE_OPENAI_WHISPER and self.openai_client:
                with open(audio_file_path, "rb") as audio_file:
                    transcript = self.openai_client.audio.transcriptions.create(
                        model="whisper-1",
                        file=audio_file,
                        language=language,
                        response_format="verbose_json"
                    )
                
                processing_time = time.time() - start_time
                
                result = {
                    "text": transcript.text,
                    "language": transcript.language if hasattr(transcript, 'language') else language,
                    "duration": transcript.duration if hasattr(transcript, 'duration') else None,
                    "processing_time": processing_time,
                    "word_count": len(transcript.text.split())
                }
                
                logger.info(f"‚úÖ OpenAI transcription completed in {processing_time:.2f}s - {result['word_count']} words")
                return result
            
            else:
                error_msg = (
                    "No transcription method available. "
                    f"USE_LOCAL_WHISPER={settings.USE_LOCAL_WHISPER}, "
                    f"USE_OPENAI_WHISPER={settings.USE_OPENAI_WHISPER}, "
                    f"whisper_model={'Loaded' if self.whisper_model else 'None'}, "
                    f"openai_client={'Loaded' if self.openai_client else 'None'}"
                )
                logger.error(f"‚ùå {error_msg}")
                raise Exception(error_msg)
            
        except Exception as e:
            logger.error(f"‚ùå Transcription failed: {str(e)}")
            raise Exception(f"Erreur lors de la transcription: {str(e)}")
    
    async def generate_summary(
        self, 
        transcription_text: str, 
        summary_type: str = "structured",
        language: str = "fr"
    ) -> Dict[str, Any]:
        """
        G√©n√®re un r√©sum√© structur√© avec GPT-4
        
        Args:
            transcription_text: Texte √† r√©sumer
            summary_type: Type de r√©sum√© (structured, bullet_points, short)
            language: Langue du r√©sum√©
        
        Returns:
            Dict contenant le r√©sum√© et les √©l√©ments structur√©s
        """
        start_time = time.time()
        
        try:
            logger.info(f"üìù Starting summarization (type: {summary_type})")
            
            # Prompt adapt√© selon le type de r√©sum√©
            system_prompt = self._get_summary_prompt(summary_type, language)
            
            # Appel √† GPT-4 via Azure
            response = self.azure_client.chat.completions.create(
                model=settings.AZURE_GPT4_DEPLOYMENT_NAME,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": transcription_text}
                ],
                temperature=0.3,
                max_tokens=2000
            )
            
            summary_text = response.choices[0].message.content
            processing_time = time.time() - start_time
            
            # Parse du r√©sum√© structur√©
            parsed_summary = self._parse_structured_summary(summary_text)
            parsed_summary["processing_time"] = processing_time
            
            logger.info(f"‚úÖ Summary generated in {processing_time:.2f}s")
            return parsed_summary
            
        except Exception as e:
            logger.error(f"‚ùå Summarization failed: {str(e)}")
            raise Exception(f"Erreur lors de la g√©n√©ration du r√©sum√©: {str(e)}")
    
    def _get_summary_prompt(self, summary_type: str, language: str) -> str:
        """Retourne le prompt syst√®me selon le type de r√©sum√©"""
        
        prompts = {
            "structured": {
                "fr": """Tu es un assistant expert en r√©sum√© de r√©unions. 
Analyse la transcription suivante et g√©n√®re un r√©sum√© structur√© en fran√ßais avec :

## üìå R√©sum√© G√©n√©ral
[Un paragraphe de synth√®se]

## üéØ Points Cl√©s
- [Point 1]
- [Point 2]
- [Point 3]

## ‚úÖ D√©cisions Prises
- [D√©cision 1]
- [D√©cision 2]

## üìã Actions √† Mener
- [Action 1 - Responsable si mentionn√©]
- [Action 2]

## üë• Participants Mentionn√©s
- [Nom 1]
- [Nom 2]

Sois pr√©cis, concis et professionnel.""",
                "en": """You are an expert meeting summarizer.
Analyze the following transcription and generate a structured summary in English with:

## üìå General Summary
[One paragraph synthesis]

## üéØ Key Points
- [Point 1]
- [Point 2]

## ‚úÖ Decisions Made
- [Decision 1]

## üìã Action Items
- [Action 1 - Owner if mentioned]

## üë• Participants Mentioned
- [Name 1]

Be precise, concise and professional."""
            },
            "bullet_points": {
                "fr": "Tu es un assistant de prise de notes. R√©sume cette transcription en 5-10 points cl√©s sous forme de liste √† puces. Sois concis et va √† l'essentiel.",
                "en": "You are a note-taking assistant. Summarize this transcription in 5-10 key bullet points. Be concise and to the point."
            },
            "short": {
                "fr": "R√©sume cette transcription en 2-3 phrases maximum. Capture l'essentiel uniquement.",
                "en": "Summarize this transcription in 2-3 sentences maximum. Capture only the essence."
            }
        }
        
        return prompts.get(summary_type, prompts["structured"]).get(language, prompts["structured"]["fr"])
    
    def _parse_structured_summary(self, summary_text: str) -> Dict[str, Any]:
        """Parse le r√©sum√© structur√© pour extraire les sections"""
        
        result = {
            "summary": summary_text,
            "key_points": [],
            "decisions": [],
            "action_items": [],
            "participants": []
        }
        
        try:
            lines = summary_text.split('\n')
            current_section = None
            
            for line in lines:
                line = line.strip()
                
                # D√©tection des sections
                if "Points Cl√©s" in line or "Key Points" in line:
                    current_section = "key_points"
                elif "D√©cisions" in line or "Decisions" in line:
                    current_section = "decisions"
                elif "Actions" in line or "Action Items" in line:
                    current_section = "action_items"
                elif "Participants" in line:
                    current_section = "participants"
                elif line.startswith("##"):
                    current_section = None
                # Extraction des items (lignes commen√ßant par - ou ‚Ä¢)
                elif line.startswith(("- ", "‚Ä¢ ", "* ")) and current_section:
                    item = line[2:].strip()
                    if item:
                        result[current_section].append(item)
            
        except Exception as e:
            logger.warning(f"‚ö†Ô∏è Could not fully parse structured summary: {e}")
        
        return result
    
    async def check_connection(self) -> bool:
        """V√©rifie la connexion √† Azure OpenAI"""
        try:
            # Test simple avec un appel minimal
            response = self.azure_client.chat.completions.create(
                model=settings.AZURE_GPT4_DEPLOYMENT_NAME,
                messages=[{"role": "user", "content": "test"}],
                max_tokens=5
            )
            return True
        except Exception as e:
            logger.error(f"‚ùå Azure OpenAI connection check failed: {e}")
            return False


# Instance globale du service
azure_service = AzureOpenAIService()
